# ê°œì„ ëœ í¸ì§‘ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„° V2
# ì¶œíŒ í¸ì§‘ì ìˆ˜ì¤€ì˜ 2-Pass í¸ì§‘ ì‹œìŠ¤í…œ

import os
import time
import json
from typing import Dict, List, Any, Optional, Callable
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from collections import defaultdict

try:
    from anthropic import Anthropic
    HAS_ANTHROPIC = True
except ImportError:
    HAS_ANTHROPIC = False

from .prompts.proofreading_prompt import get_proofreading_prompt
from .prompts.polishing_prompt import get_polishing_prompt
from .utils.diff_generator import DiffGenerator, generate_markdown_diff
from .models.document import Document

# ëª¨ë¸ë³„ ê°€ê²©
PRICING_USD_PER_MTOK = {
    "claude-3-5-sonnet-20241022": {
        "input": float(os.getenv("CLAUDE_SONNET_35_INPUT_MTOK", "3.00")),
        "output": float(os.getenv("CLAUDE_SONNET_35_OUTPUT_MTOK", "15.00")),
    },
    "claude-3-5-sonnet-20240620": {
        "input": float(os.getenv("CLAUDE_SONNET_35_INPUT_MTOK", "3.00")),
        "output": float(os.getenv("CLAUDE_SONNET_35_OUTPUT_MTOK", "15.00")),
    },
    "claude-3-7-sonnet-20250219": {
        "input": float(os.getenv("CLAUDE_SONNET_37_INPUT_MTOK", "3.00")),
        "output": float(os.getenv("CLAUDE_SONNET_37_OUTPUT_MTOK", "15.00")),
    },
    "claude-haiku-4-5-20251001": {
        "input": float(os.getenv("CLAUDE_HAIKU_45_INPUT_MTOK", "1.00")),
        "output": float(os.getenv("CLAUDE_HAIKU_45_OUTPUT_MTOK", "5.00")),
    },
}


def _get_model_pricing(model_name: str) -> dict:
    """ëª¨ë¸ë³„ ê°€ê²© ì •ë³´"""
    return PRICING_USD_PER_MTOK.get(model_name, {"input": 0.0, "output": 0.0})


class EditOrchestratorV2:
    """
    ì¶œíŒ í¸ì§‘ì ìˆ˜ì¤€ì˜ 2-Pass í¸ì§‘ ì‹œìŠ¤í…œ
    
    Pass 1: ê¸°ê³„ì  êµì • (ë§ì¶¤ë²•, ë„ì–´ì“°ê¸°, ë¬¸ì¥ë¶€í˜¸)
    Pass 2: ì°½ì˜ì  ìœ¤ë¬¸ (ë¬¸ì¥ êµ¬ì¡°, ê°€ë…ì„±, ë¦¬ë“¬ê°)
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.api_key = os.getenv('ANTHROPIC_API_KEY')
        self.diff_generator = DiffGenerator()
        
        if not HAS_ANTHROPIC:
            print("âš ï¸  anthropic íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        if not self.api_key:
            print("âš ï¸  ANTHROPIC_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    def load_document(self, file_path: str, domain: str = "business", 
                     target_audience: str = "general") -> Document:
        """ë¬¸ì„œ ë¡œë“œ"""
        file_path = Path(file_path)
        
        if not file_path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
        
        # íŒŒì¼ ì½ê¸°
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
        except UnicodeDecodeError:
            with open(file_path, 'r', encoding='cp949') as f:
                content = f.read()
        
        # ì œëª© ì¶”ì¶œ
        title = "Untitled"
        if content.startswith('# '):
            title = content.split('\n')[0].replace('# ', '').strip()
        
        doc = Document(
            id=file_path.stem,
            title=title,
            content=content,
            domain=domain,
            target_audience=target_audience,
        )
        
        return doc
    
    def _split_into_chunks(self, text: str, max_chars: int = 4000) -> List[str]:
        """
        í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í• 
        
        ë§ˆí¬ë‹¤ìš´ êµ¬ì¡°ë¥¼ ìœ ì§€í•˜ë©´ì„œ ë¶„í• :
        - ## Section ë‹¨ìœ„ë¡œ ìš°ì„  ë¶„í• 
        - ë„ˆë¬´ í¬ë©´ ë‹¨ë½ ë‹¨ìœ„ë¡œ ì¶”ê°€ ë¶„í• 
        """
        # Section ë‹¨ìœ„ë¡œ ë¶„í• 
        sections = []
        current_section = []
        
        lines = text.split('\n')
        
        for line in lines:
            # Section í—¤ë” ê°ì§€
            if line.startswith('## Section'):
                if current_section:
                    sections.append('\n'.join(current_section))
                current_section = [line]
            else:
                current_section.append(line)
        
        if current_section:
            sections.append('\n'.join(current_section))
        
        # ë„ˆë¬´ í° ì„¹ì…˜ì€ ì¶”ê°€ ë¶„í• 
        chunks = []
        for section in sections:
            if len(section) <= max_chars:
                chunks.append(section)
            else:
                # ë‹¨ë½ ë‹¨ìœ„ë¡œ ë¶„í• 
                paragraphs = section.split('\n\n')
                current_chunk = ""
                
                for para in paragraphs:
                    if len(current_chunk) + len(para) + 2 <= max_chars:
                        current_chunk += para + '\n\n'
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = para + '\n\n'
                
                if current_chunk:
                    chunks.append(current_chunk.strip())
        
        return chunks
    
    def _call_claude(self, prompt: str, model: str = "claude-3-7-sonnet-20250219",
                    temperature: float = 0.3) -> tuple:
        """
        Claude API í˜¸ì¶œ
        
        Returns:
            (ì‘ë‹µ í…ìŠ¤íŠ¸, input_tokens, output_tokens)
        """
        if not self.api_key or not HAS_ANTHROPIC:
            return ("", 0, 0)
        
        try:
            client = Anthropic(api_key=self.api_key)
            
            response = client.messages.create(
                model=model,
                max_tokens=16000,
                temperature=temperature,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
            input_tok = 0
            output_tok = 0
            try:
                usage_obj = getattr(response, "usage", None)
                if usage_obj:
                    input_tok = int(getattr(usage_obj, "input_tokens", 0) or 0)
                    output_tok = int(getattr(usage_obj, "output_tokens", 0) or 0)
            except:
                pass
            
            result_text = response.content[0].text
            
            # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°
            if "```" in result_text:
                # ```markdown ë˜ëŠ” ``` ë¡œ ê°ì‹¸ì§„ ê²½ìš°
                import re
                match = re.search(r'```(?:markdown)?\n(.*?)\n```', result_text, re.DOTALL)
                if match:
                    result_text = match.group(1)
            
            return (result_text.strip(), input_tok, output_tok)
            
        except Exception as e:
            print(f"âš ï¸  Claude API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return ("", 0, 0)
    
    def pass1_proofread(self, text: str, max_workers: int = 10) -> Dict[str, Any]:
        """
        Pass 1: ê¸°ê³„ì  êµì •
        
        ë§ì¶¤ë²•, ë„ì–´ì“°ê¸°, ë¬¸ì¥ë¶€í˜¸ë§Œ ìˆ˜ì •
        ë¬¸ì¥ êµ¬ì¡°ëŠ” ë³€ê²½í•˜ì§€ ì•ŠìŒ
        """
        print("\n" + "=" * 80)
        print("ğŸ“ Pass 1: ê¸°ê³„ì  êµì • (ë§ì¶¤ë²•, ë„ì–´ì“°ê¸°, ë¬¸ì¥ë¶€í˜¸)")
        print("=" * 80)
        
        start_time = time.time()
        
        # ì²­í¬ ë¶„í• 
        chunks = self._split_into_chunks(text, max_chars=4000)
        print(f"\n[êµì •] {len(chunks)}ê°œ ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ({max_workers}ê°œ ì›Œì»¤)...")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        results = {}
        total_input_tokens = 0
        total_output_tokens = 0
        completed_count = 0
        
        def process_chunk(chunk_info):
            i, chunk = chunk_info
            chunk_start = time.time()
            
            if not chunk.strip():
                return (i, chunk, 0, 0, time.time() - chunk_start)
            
            prompt = get_proofreading_prompt(chunk)
            corrected, input_tok, output_tok = self._call_claude(
                prompt,
                model="claude-3-7-sonnet-20250219",
                temperature=0.2  # ë‚®ì€ temperatureë¡œ ì¼ê´€ì„± í™•ë³´
            )
            
            if not corrected:
                corrected = chunk
            
            elapsed = time.time() - chunk_start
            return (i, corrected, input_tok, output_tok, elapsed)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(process_chunk, (i, chunk)): i
                for i, chunk in enumerate(chunks)
            }
            
            for future in as_completed(futures):
                i, corrected, input_tok, output_tok, elapsed = future.result()
                completed_count += 1
                pending = len(chunks) - completed_count
                
                results[i] = corrected
                total_input_tokens += input_tok
                total_output_tokens += output_tok
                
                print(f"  âœ“ [{completed_count:2d}/{len(chunks)}] ì²­í¬ {i+1:2d} ì™„ë£Œ "
                      f"({len(corrected):5d} chars, {elapsed:5.1f}s) | ë‚¨ì€ì‘ì—…: {pending:2d}",
                      flush=True)
        
        # ì¬ê²°í•©
        corrected_text = '\n\n'.join([results[i] for i in range(len(chunks))])
        
        processing_time = time.time() - start_time
        
        print(f"\nâœ… Pass 1 ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
        
        return {
            'text': corrected_text,
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens,
            'processing_time': processing_time,
            'model': 'claude-3-7-sonnet-20250219'
        }
    
    def pass2_polish(self, text: str, max_workers: int = 10) -> Dict[str, Any]:
        """
        Pass 2: ì°½ì˜ì  ìœ¤ë¬¸
        
        ë¬¸ì¥ êµ¬ì¡°, ê°€ë…ì„±, ë¦¬ë“¬ê° ê°œì„ 
        ë²ˆì—­ì²´ ì œê±°, ê¸´ ë¬¸ì¥ ë¶„ë¦¬
        """
        print("\n" + "=" * 80)
        print("âœ¨ Pass 2: ì°½ì˜ì  ìœ¤ë¬¸ (ë¬¸ì¥ êµ¬ì¡°, ê°€ë…ì„±, ë¦¬ë“¬ê°)")
        print("=" * 80)
        
        start_time = time.time()
        
        # ì²­í¬ ë¶„í• 
        chunks = self._split_into_chunks(text, max_chars=4000)
        print(f"\n[ìœ¤ë¬¸] {len(chunks)}ê°œ ì²­í¬ ë³‘ë ¬ ì²˜ë¦¬ ì¤‘ ({max_workers}ê°œ ì›Œì»¤)...")
        
        # ë³‘ë ¬ ì²˜ë¦¬
        results = {}
        total_input_tokens = 0
        total_output_tokens = 0
        completed_count = 0
        
        def process_chunk(chunk_info):
            i, chunk = chunk_info
            chunk_start = time.time()
            
            if not chunk.strip():
                return (i, chunk, 0, 0, time.time() - chunk_start)
            
            prompt = get_polishing_prompt(chunk)
            polished, input_tok, output_tok = self._call_claude(
                prompt,
                model="claude-3-7-sonnet-20250219",
                temperature=0.5  # ì•½ê°„ ë†’ì€ temperatureë¡œ ì°½ì˜ì„± í™•ë³´
            )
            
            if not polished:
                polished = chunk
            
            elapsed = time.time() - chunk_start
            return (i, polished, input_tok, output_tok, elapsed)
        
        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(process_chunk, (i, chunk)): i
                for i, chunk in enumerate(chunks)
            }
            
            for future in as_completed(futures):
                i, polished, input_tok, output_tok, elapsed = future.result()
                completed_count += 1
                pending = len(chunks) - completed_count
                
                results[i] = polished
                total_input_tokens += input_tok
                total_output_tokens += output_tok
                
                print(f"  âœ“ [{completed_count:2d}/{len(chunks)}] ì²­í¬ {i+1:2d} ì™„ë£Œ "
                      f"({len(polished):5d} chars, {elapsed:5.1f}s) | ë‚¨ì€ì‘ì—…: {pending:2d}",
                      flush=True)
        
        # ì¬ê²°í•©
        polished_text = '\n\n'.join([results[i] for i in range(len(chunks))])
        
        processing_time = time.time() - start_time
        
        print(f"\nâœ… Pass 2 ì™„ë£Œ ({processing_time:.1f}ì´ˆ)")
        
        return {
            'text': polished_text,
            'input_tokens': total_input_tokens,
            'output_tokens': total_output_tokens,
            'processing_time': processing_time,
            'model': 'claude-3-7-sonnet-20250219'
        }
    
    def edit_document(self, doc: Document, enable_pass2: bool = True,
                     max_workers: int = 10, progress_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        ì „ì²´ í¸ì§‘ í”„ë¡œì„¸ìŠ¤
        
        Args:
            doc: ë¬¸ì„œ ê°ì²´
            enable_pass2: Pass 2 (ìœ¤ë¬¸) í™œì„±í™” ì—¬ë¶€
            max_workers: ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜
            progress_callback: ì§„í–‰ë¥  ì½œë°±
        
        Returns:
            í¸ì§‘ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        print("\n" + "=" * 80)
        print("ğŸ“š ì¶œíŒ í¸ì§‘ì ìˆ˜ì¤€ì˜ 2-Pass í¸ì§‘ ì‹œìŠ¤í…œ")
        print("=" * 80)
        print(f"\në¬¸ì„œ: {doc.title}")
        print(f"ë‹¨ì–´ ìˆ˜: {doc.word_count:,}ê°œ")
        print(f"ë¬¸ì ìˆ˜: {len(doc.content):,}ì")
        
        start_time = time.time()
        original_text = doc.content
        
        # Pass 1: ê¸°ê³„ì  êµì •
        if progress_callback:
            progress_callback('pass1_proofread', 0.0)
        
        pass1_result = self.pass1_proofread(original_text, max_workers=max_workers)
        corrected_text = pass1_result['text']
        
        if progress_callback:
            progress_callback('pass1_proofread', 1.0)
        
        # Pass 2: ì°½ì˜ì  ìœ¤ë¬¸
        polished_text = corrected_text
        pass2_result = None
        
        if enable_pass2:
            if progress_callback:
                progress_callback('pass2_polish', 0.0)
            
            pass2_result = self.pass2_polish(corrected_text, max_workers=max_workers)
            polished_text = pass2_result['text']
            
            if progress_callback:
                progress_callback('pass2_polish', 1.0)
        
        # í†µê³„ ê³„ì‚°
        total_time = time.time() - start_time
        
        # í† í° ì‚¬ìš©ëŸ‰ ì§‘ê³„
        usage_by_model = defaultdict(lambda: {"input_tokens": 0, "output_tokens": 0, "requests": 0})
        
        model = pass1_result['model']
        usage_by_model[model]["input_tokens"] += pass1_result['input_tokens']
        usage_by_model[model]["output_tokens"] += pass1_result['output_tokens']
        usage_by_model[model]["requests"] += 1
        
        if pass2_result:
            model = pass2_result['model']
            usage_by_model[model]["input_tokens"] += pass2_result['input_tokens']
            usage_by_model[model]["output_tokens"] += pass2_result['output_tokens']
            usage_by_model[model]["requests"] += 1
        
        # ë¹„ìš© ê³„ì‚°
        print("\n" + "=" * 80)
        print("ğŸ’° í† í° ì‚¬ìš©ëŸ‰ ë° ì˜ˆìƒ ë¹„ìš©")
        print("=" * 80)
        
        grand_input = 0
        grand_output = 0
        grand_cost = 0.0
        
        for model, agg in usage_by_model.items():
            inp = agg["input_tokens"]
            outp = agg["output_tokens"]
            reqs = agg["requests"]
            grand_input += inp
            grand_output += outp
            
            price = _get_model_pricing(model)
            cost = (inp / 1_000_000.0) * price["input"] + (outp / 1_000_000.0) * price["output"]
            grand_cost += cost
            
            print(f"\n{model} ({reqs}íšŒ í˜¸ì¶œ)")
            print(f"  Input:  {inp:>10,} tokens Ã— ${price['input']:.2f}/M = ${(inp/1_000_000)*price['input']:.4f}")
            print(f"  Output: {outp:>10,} tokens Ã— ${price['output']:.2f}/M = ${(outp/1_000_000)*price['output']:.4f}")
            print(f"  ì†Œê³„: ${cost:.4f}")
        
        print(f"\nğŸ’° ì´ ì˜ˆìƒ ë¹„ìš©: ${grand_cost:.4f} USD")
        print(f"   (Input: {grand_input:,} tok | Output: {grand_output:,} tok)")
        print(f"\nâ±ï¸  ì´ ì†Œìš”ì‹œê°„: {total_time:.1f}ì´ˆ")
        print("=" * 80)
        
        # ë³€ê²½ì‚¬í•­ í†µê³„
        diff_stats = self.diff_generator.generate_summary(original_text, polished_text)
        
        return {
            'final_text': polished_text,
            'original_text': original_text,
            'pass1_text': corrected_text,
            'pass2_text': polished_text if enable_pass2 else None,
            'processing_time': total_time,
            'usage_summary': dict(usage_by_model),
            'total_cost': grand_cost,
            'diff_stats': diff_stats,
            'quality_score': 90.0,  # ê¸°ë³¸ í’ˆì§ˆ ì ìˆ˜
        }
    
    def generate_comparison_report(self, original: str, edited: str, 
                                   output_path: Optional[Path] = None) -> str:
        """
        í¸ì§‘ ì „í›„ ë¹„êµ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            original: ì›ë³¸ í…ìŠ¤íŠ¸
            edited: í¸ì§‘ëœ í…ìŠ¤íŠ¸
            output_path: ì €ì¥ ê²½ë¡œ (ì„ íƒ)
        
        Returns:
            ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì˜ ë¹„êµ ë¦¬í¬íŠ¸
        """
        report = generate_markdown_diff(original, edited, title="í¸ì§‘ ì „í›„ ë¹„êµ")
        
        if output_path:
            output_path = Path(output_path)
            output_path.parent.mkdir(parents=True, exist_ok=True)
            output_path.write_text(report, encoding='utf-8')
            print(f"\nğŸ“Š ë¹„êµ ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")
        
        return report
