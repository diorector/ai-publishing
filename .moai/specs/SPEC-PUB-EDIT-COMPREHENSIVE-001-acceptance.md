# SPEC-PUB-EDIT-COMPREHENSIVE-001: ìˆ˜ìš© ê¸°ì¤€ ë° í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

**Version**: 1.0.0
**Status**: DRAFT
**Created**: 2025-11-18

---

## ğŸ“‹ ê°œìš”

ì´ ë¬¸ì„œëŠ” í¬ê´„ì  í¸ì§‘ ë„êµ¬ì˜ ì™„ì„±ë„ë¥¼ ê²€ì¦í•˜ê¸° ìœ„í•œ **êµ¬ì²´ì ì¸ ìˆ˜ìš© ê¸°ì¤€ê³¼ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤**ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. ê° ê¸°ì¤€ì€ Given-When-Then í˜•ì‹ì˜ ìë™í™”ëœ í…ŒìŠ¤íŠ¸ë¡œ ê²€ì¦ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤.

---

## ğŸ¯ í’ˆì§ˆ ê²Œì´íŠ¸ (Quality Gates)

### 1ë‹¨ê³„: ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ (Unit Tests)

**ìš”êµ¬ì‚¬í•­**:
- ëª¨ë“  ëª¨ë“ˆ ìµœì†Œ 80% ì½”ë“œ ì»¤ë²„ë¦¬ì§€
- ëª¨ë“  ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ í†µê³¼ (0 ì‹¤íŒ¨)
- í‰ê·  ì‘ë‹µ ì‹œê°„ <5ì´ˆ/ìš”ì²­

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# tests/test_orchestrator.py
def test_document_loading():
    """ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ë¡œë“œ ë° íŒŒì‹±"""
    doc = load_document("test_doc.md")
    assert doc.title is not None
    assert len(doc.content) > 0
    assert doc.word_count > 0

def test_document_analysis():
    """ë¬¸ì„œ ë¶„ì„ ë° ë„ë©”ì¸ ë¶„ë¥˜"""
    doc = create_test_document(domain="startup")
    analysis = orchestrator.analyze_document(doc)
    assert analysis.domain == "startup"
    assert len(analysis.issues) > 0

def test_checkpoint_saving():
    """ì²´í¬í¬ì¸íŠ¸ ì €ì¥ ë° ë³µêµ¬"""
    doc = create_test_document()
    orchestrator.save_checkpoint(doc, "proofreading")
    restored = orchestrator.load_checkpoint(doc.id, "proofreading")
    assert restored.id == doc.id
```

### 2ë‹¨ê³„: í†µí•© í…ŒìŠ¤íŠ¸ (Integration Tests)

**ìš”êµ¬ì‚¬í•­**:
- 3ê°œ ëª¨ë“ˆ ëª¨ë‘ ì •ìƒ ë™ì‘
- ê° ë‹¨ê³„ ê°„ ë°ì´í„° ì „ë‹¬ ë¬´ê²°ì„±
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ì ì ˆí•œ ë³µêµ¬

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# tests/test_integration.py
@pytest.mark.asyncio
async def test_proofreading_only():
    """êµì •ë§Œ ì‹¤í–‰"""
    doc = load_test_document("startup", size="small")
    result = await orchestrator.edit_comprehensive(
        doc,
        stages=[EditStage.PROOFREADING]
    )
    assert result.quality_score >= 75
    assert len(result.changes) > 0

@pytest.mark.asyncio
async def test_all_stages_sequential():
    """3ë‹¨ê³„ ìˆœì°¨ ì‹¤í–‰"""
    doc = load_test_document("startup", size="medium")
    result = await orchestrator.edit_comprehensive(doc)
    assert result.quality_score >= 80
    # ê° ë‹¨ê³„ ê²°ê³¼ í™•ì¸
    assert result.proofreading_score >= 75
    assert result.fact_checking_score >= 75
    assert result.copywriting_score >= 75

@pytest.mark.asyncio
async def test_error_recovery():
    """ì˜¤ë¥˜ ë°œìƒ ë° ë³µêµ¬"""
    doc = load_test_document()
    # ì˜ë„ì ìœ¼ë¡œ ì˜¤ë¥˜ ì£¼ì…
    with patch("anthropic.Anthropic.messages.create") as mock:
        mock.side_effect = APIError("Service unavailable")

        try:
            await orchestrator.edit_comprehensive(doc)
        except APIError:
            pass

        # ë³µêµ¬ ê°€ëŠ¥í•œì§€ í™•ì¸
        checkpoint = orchestrator.load_checkpoint(doc.id)
        assert checkpoint is not None
```

### 3ë‹¨ê³„: ì—”ë“œ-íˆ¬-ì—”ë“œ í…ŒìŠ¤íŠ¸ (E2E Tests)

**ìš”êµ¬ì‚¬í•­**:
- ì‹¤ì œ ë°ì´í„°ë¡œ ì „ì²´ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
- ìµœì¢… ê²°ê³¼ í’ˆì§ˆ â‰¥90ì 
- ì²˜ë¦¬ ì‹œê°„ ê¸°ì¤€ ë‚´ ì™„ë£Œ

**ì²´í¬ë¦¬ìŠ¤íŠ¸**:
```python
# tests/test_e2e.py
@pytest.mark.asyncio
async def test_laf_document_editing():
    """LAF ë¬¸ì„œ ì „ì²´ í¸ì§‘ (ì‹¤ì œ ë°ì´í„°)"""
    # LAF ì‹¤ì œ íŒŒì¼ ë¡œë“œ
    doc = load_document("input/laf_translated.md")

    # ì „ì²´ í¸ì§‘
    start = time.time()
    result = await orchestrator.edit_comprehensive(doc)
    elapsed = time.time() - start

    # í’ˆì§ˆ ê²€ì¦
    assert result.quality_score >= 90, "í’ˆì§ˆ ì ìˆ˜ ë¯¸ë‹¬"
    assert result.proofreading_errors < 10, "êµì • ì˜¤ë¥˜ ì´ˆê³¼"
    assert result.fact_check_issues < 5, "êµì—´ ì´ìŠˆ ì´ˆê³¼"
    assert result.copywriting_score >= 85, "ìœ¤ë¬¸ ì ìˆ˜ ë¯¸ë‹¬"

    # ì„±ëŠ¥ ê²€ì¦
    word_count = len(doc.content.split())
    expected_time = (word_count / 10000) * 7200  # 10Kë‹¨ì–´ë‹¹ 2ì‹œê°„
    assert elapsed < expected_time * 1.2, "ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼"

    # ê²°ê³¼ ì €ì¥
    save_result(result, "output/laf_edited.md")
```

---

## âœ… ê¸°ëŠ¥ë³„ ìˆ˜ìš© ê¸°ì¤€

### A. êµì •(Proofreading) ëª¨ë“ˆ

#### A.1 ê¸°ë³¸ êµì • ê¸°ëŠ¥

**ì‹œë‚˜ë¦¬ì˜¤ 1: ë„ì–´ì“°ê¸° ì˜¤ë¥˜ êµì •**

```gherkin
Given: ë„ì–´ì“°ê¸° ì˜¤ë¥˜ê°€ ìˆëŠ” í•œê¸€ í…ìŠ¤íŠ¸
When: êµì • ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… ëª¨ë“  ë„ì–´ì“°ê¸° ì˜¤ë¥˜ ìˆ˜ì •
  âœ… ì›ë¬¸ê³¼ ìˆ˜ì •ë³¸ ëª…í™•íˆ ì œì‹œ
  âœ… ë³€ê²½ ì‚¬í•­ ë¡œê·¸ ê¸°ë¡
```

**í…ŒìŠ¤íŠ¸ ë°ì´í„°**:
```python
test_cases = [
    ("í•œê¸€ë§ì¶¤ë²•", "í•œê¸€ ë§ì¶¤ë²•"),
    ("ì´ë¥¼í…Œë©´ì´ë ‡ê²Œ", "ì´ë¥¼í…Œë©´ ì´ë ‡ê²Œ"),
    ("GoogleíšŒì‚¬", "Google íšŒì‚¬"),
]

@pytest.mark.parametrize("original,expected", test_cases)
async def test_spacing_correction(original, expected):
    agent = FormatExpertAgent(config)
    result = await agent.process_chunk(original)
    assert expected in result.edited_text
```

#### A.2 ì™¸êµ­ì–´ í‘œê¸°ë²• ì¼ê´€ì„±

**ì‹œë‚˜ë¦¬ì˜¤ 2: ê¸°ì—…ëª… í‘œê¸° ì¼ê´€ì„±**

```gherkin
Given: ê°™ì€ ê¸°ì—…ëª…ì´ ì—¬ëŸ¬ ë°©ì‹ìœ¼ë¡œ í‘œê¸°ëœ ë¬¸ì„œ
When: êµì • ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… ëª¨ë“  "Google" â†’ "êµ¬ê¸€" í†µì¼
  âœ… "Amazon" â†’ "ì•„ë§ˆì¡´" í†µì¼
  âœ… ë¶ˆê°€ì§€ í‘œê¸°ë²• í”Œë˜ê·¸ í‘œì‹œ
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
async def test_notation_consistency():
    """ì™¸êµ­ì–´ í‘œê¸°ë²• ì¼ê´€ì„±"""
    text = """Googleì€ ê²€ìƒ‰ ì—”ì§„ìœ¼ë¡œ ìœ ëª…í•©ë‹ˆë‹¤.
êµ¬ê¸€ì€ AIì—ë„ íˆ¬ìí•˜ê³  ìˆìŠµë‹ˆë‹¤.
GOOGLEì˜ ìíšŒì‚¬ë„ ìˆìŠµë‹ˆë‹¤."""

    result = await agent.process_chunk(text)

    # ëª¨ë‘ ê°™ì€ í‘œê¸°ë²•ìœ¼ë¡œ í†µì¼ë˜ì–´ì•¼ í•¨
    google_count = result.edited_text.count("êµ¬ê¸€")
    other_forms = result.edited_text.count("Google") + \
                   result.edited_text.count("GOOGLE")

    assert other_forms == 0, "í‘œê¸°ë²• ë¯¸í†µì¼"
    assert google_count == 3, "ëª¨ë“  í‘œê¸° í†µì¼ í™•ì¸"
```

#### A.3 í’ˆì§ˆ ê¸°ì¤€

```python
class ProofreadingAcceptanceCriteria:
    """êµì • ëª¨ë“ˆ ìˆ˜ìš© ê¸°ì¤€"""

    def validate(self, result: EditResult) -> bool:
        checks = {
            "spelling_accuracy": result.spelling_errors < 1,  # <1% ì˜¤ë¥˜
            "spacing_consistency": result.spacing_score > 0.95,
            "notation_uniformity": result.notation_score > 0.95,
            "processing_time": result.processing_time < 300,  # <5ë¶„/ì²­í¬
            "quality_score": result.quality_score >= 85,
        }

        return all(checks.values())
```

---

### B. êµì—´(Fact-checking) ëª¨ë“ˆ

#### B.1 íŒ©íŠ¸ ê²€ì¦ ê¸°ëŠ¥

**ì‹œë‚˜ë¦¬ì˜¤ 3: í†µê³„ ê²€ì¦**

```gherkin
Given: í†µê³„ ìˆ˜ì¹˜ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸
When: êµì—´ ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… Context7ë¡œ 2025ë…„ ìµœì‹  ì •ë³´ ê²€ìƒ‰
  âœ… ì •ë³´ì˜ ì‹ ë¢°ë„ í‰ì  ì œì‹œ
  âœ… êµ¬ì‹ ì •ë³´ ì‹ë³„ ë° ì£¼ì„ ì¶”ê°€
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.asyncio
async def test_statistics_verification():
    """í†µê³„ ìˆ˜ì¹˜ ê²€ì¦"""
    text = """
    2023ë…„ í†µê³„ì— ë”°ë¥´ë©´ ìŠ¤íƒ€íŠ¸ì—…ì€ 5,000ê°œ ì´ìƒì´ì—ˆìŠµë‹ˆë‹¤.
    ì „ ì„¸ê³„ AI ì‹œì¥ì€ 5ì¡° ë‹¬ëŸ¬ ê·œëª¨ì…ë‹ˆë‹¤.
    """

    fact_checker = FactCheckerAgent(config)
    result = await fact_checker.process_chunk(text)

    # ê²€ì¦ ê²°ê³¼ í™•ì¸
    assert len(result.verified_items) >= 2, "ê²€ì¦ í•­ëª© ë¶€ì¡±"
    assert all(item.source is not None for item in result.verified_items)
    assert all(item.confidence >= 0.7 for item in result.verified_items)
```

#### B.2 êµ¬ì‹ ì •ë³´ ì‹ë³„

**ì‹œë‚˜ë¦¬ì˜¤ 4: êµ¬ì‹ ì •ë³´ ì£¼ì„**

```gherkin
Given: 2023ë…„ ì´ì „ ì •ë³´ê°€ í¬í•¨ëœ ë¬¸ì„œ
When: êµì—´ ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… êµ¬ì‹ ì •ë³´ ê°ì§€
  âœ… 2025ë…„ ìµœì‹  ì •ë³´ì™€ í•¨ê»˜ ì£¼ì„ ì¶”ê°€
  âœ… ì›ë¬¸ì€ ìœ ì§€í•˜ë˜ ì£¼ì„ìœ¼ë¡œ í‘œì‹œ
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.asyncio
async def test_deprecated_annotation():
    """êµ¬ì‹ ì •ë³´ ì£¼ì„"""
    text = "2023ë…„ ê¸°ì¤€ ë¹„íŠ¸ì½”ì¸ì€ 3ë§Œ ë‹¬ëŸ¬ì˜€ìŠµë‹ˆë‹¤."

    result = await fact_checker.process_chunk(text)

    # êµ¬ì‹ ì •ë³´ ì£¼ì„ì´ ì¶”ê°€ë˜ì–´ì•¼ í•¨
    assert "í¸ì§‘ì ì£¼" in result.edited_text or \
           "2025ë…„ ê¸°ì¤€" in result.edited_text

    # ì›ë¬¸ì€ ìœ ì§€
    assert "2023ë…„" in result.edited_text
    assert "3ë§Œ ë‹¬ëŸ¬" in result.edited_text
```

#### B.3 Context7 í†µí•© ê²€ì¦

**ì‹œë‚˜ë¦¬ì˜¤ 5: Context7 ê²€ìƒ‰**

```gherkin
Given: ê²€ì¦ í•„ìš” í•­ëª© ëª©ë¡
When: Context7 MCPë¡œ ì •ë³´ ê²€ìƒ‰
Then:
  âœ… 2025ë…„ ê¸°ì¤€ ìµœì‹  ì •ë³´ ë°˜í™˜
  âœ… ì—¬ëŸ¬ ì¶œì²˜ ì œì‹œ
  âœ… ì‹ ë¢°ë„ ì ìˆ˜ ì œê³µ
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.asyncio
async def test_context7_integration():
    """Context7 í†µí•©"""
    query = "í•œêµ­ ìŠ¤íƒ€íŠ¸ì—… í˜„í™© 2025"

    context7 = Context7Client(config)
    results = await context7.search(
        query=query,
        domain="startup",
        year=2025
    )

    # Context7 ì‘ë‹µ ê²€ì¦
    assert len(results) > 0, "ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ"
    assert all(r.source is not None for r in results)
    assert all(r.confidence is not None for r in results)
    assert max(r.confidence for r in results) > 0.8, "ì‹ ë¢°ë„ ë‚®ìŒ"
```

#### B.4 í’ˆì§ˆ ê¸°ì¤€

```python
class FactCheckingAcceptanceCriteria:
    """êµì—´ ëª¨ë“ˆ ìˆ˜ìš© ê¸°ì¤€"""

    def validate(self, result: EditResult) -> bool:
        checks = {
            "verification_coverage": result.verified_items / \
                                   result.total_items > 0.9,
            "confidence_threshold": result.avg_confidence > 0.7,
            "deprecated_flagging": len(result.deprecated_items) > 0 or \
                                  result.no_issues,
            "processing_time": result.processing_time < 600,  # <10ë¶„/ì„¹ì…˜
            "quality_score": result.quality_score >= 80,
        }

        return all(checks.values())
```

---

### C. ìœ¤ë¬¸(Copywriting) ëª¨ë“ˆ

#### C.1 ë¬¸ì¥ ê°œì„ 

**ì‹œë‚˜ë¦¬ì˜¤ 6: ë³µë¬¸ ë‹¨ë¬¸í™”**

```gherkin
Given: ë³µì¡í•œ ë³µë¬¸ì´ ìˆëŠ” í…ìŠ¤íŠ¸
When: ìœ¤ë¬¸ ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… ë³µë¬¸ì„ 2-3ê°œ ë‹¨ë¬¸ìœ¼ë¡œ ë¶„í•´
  âœ… ì˜ë¯¸ ì†ì‹¤ ì—†ìŒ (100% ë³´ì¡´)
  âœ… ê°€ë…ì„± ì ìˆ˜ ê°œì„ 
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.asyncio
async def test_sentence_simplification():
    """ë³µë¬¸ ë‹¨ìˆœí™”"""
    original = "ìš°ë¦¬ê°€ ê°œë°œí•œ AI ëª¨ë¸ì€ ê¸°ì¡´ ëª¨ë¸ ëŒ€ë¹„ \
30% ë” ë¹ ë¥´ë©´ì„œë„ ì •í™•ë„ëŠ” 5% ë†’ì•„ì„œ ì‹œì¥ì—ì„œ ê²½ìŸë ¥ì´ ìˆë‹¤."

    copywriter = CopywritingExpertAgent(config)
    result = await copywriter.process_paragraph(original)

    # ê²€ì¦
    sentence_count = len(result.edited_text.split('.'))
    assert sentence_count > 1, "ë¶„í•´ ì•ˆ ë¨"

    # ì˜ë¯¸ ë™ë“±ì„± ê²€ì¦ (ì˜ë¯¸ë¡ ì  ìœ ì‚¬ë„ >0.9)
    similarity = semantic_similarity(original, result.edited_text)
    assert similarity > 0.9, "ì˜ë¯¸ ì†ì‹¤"

    # ê°€ë…ì„± ê°œì„  (flesch score ì¦ê°€)
    assert result.readability_score > \
           calculate_flesch_score(original), "ê°€ë…ì„± ë¯¸ê°œì„ "
```

#### C.2 í†¤ì•¤ë§¤ë„ˆ ì¼ê´€ì„±

**ì‹œë‚˜ë¦¬ì˜¤ 7: ì¡´ëŒ“ë§ ì¼ê´€ì„±**

```gherkin
Given: ì¡´ëŒ“ë§ê³¼ ë°˜ë§ì´ ì„ì¸ ë¬¸ì„œ
When: ìœ¤ë¬¸ ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… ëª¨ë“  ë¬¸ì¥ì„ ì¡´ëŒ“ë§ë¡œ í†µì¼
  âœ… ì €ì ì˜ë„ ë³´ì¡´
  âœ… ì „ë¬¸ì„± ìœ ì§€
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.asyncio
async def test_tone_consistency():
    """í†¤ì•¤ë§¤ë„ˆ ì¼ê´€ì„±"""
    text = """
    ìŠ¤íƒ€íŠ¸ì—…ì€ ë¹ ë¥´ê²Œ ì„±ì¥í•œë‹¤. ê·¸ë“¤ì€ í˜ì‹ ì ì´ê³ ,
    ì‹œì¥ì— ìƒˆë¡œìš´ ê°€ì¹˜ë¥¼ ì œì‹œí•©ë‹ˆë‹¤.
    """

    result = await copywriter.process_paragraph(text)

    # ì¡´ëŒ“ë§ ì¼ê´€ì„± ê²€ì¦
    tone_score = evaluate_tone_consistency(result.edited_text)
    assert tone_score > 0.95, "í†¤ì•¤ë§¤ë„ˆ ë¯¸í†µì¼"

    # ì¡´ëŒ“ë§ë§Œ ì‚¬ìš© í™•ì¸
    assert "-ìŠµë‹ˆë‹¤" in result.edited_text or \
           "-í•©ë‹ˆë‹¤" in result.edited_text or \
           "-ë‹ˆë‹¤" in result.edited_text
```

#### C.3 ë²ˆì—­ì²´ ì œê±°

**ì‹œë‚˜ë¦¬ì˜¤ 8: ë²ˆì—­ì²´ í‘œí˜„ ì œê±°**

```gherkin
Given: ë²ˆì—­ì²´ í‘œí˜„ì´ ìˆëŠ” í•œê¸€ ë¬¸ì„œ
When: ìœ¤ë¬¸ ëª¨ë“ˆ ì‹¤í–‰
Then:
  âœ… "~ë˜ì–´ì§€ë‹¤", "~ê²ƒì´ë‹¤" ë“± ì œê±°
  âœ… ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ë³€í™˜
  âœ… ì›ì˜ë¯¸ ì™„ë²½ ë³´ì¡´
```

**í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤**:
```python
@pytest.mark.parametrize("translated,natural", [
    ("ì‹œìŠ¤í…œì— ì˜í•´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë˜ì–´ì§„ë‹¤",
     "ì‹œìŠ¤í…œì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤"),
    ("ì´ê²ƒì´ í•µì‹¬ì´ë‹¤",
     "ì´ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤"),
    ("~í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤",
     "~í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•©ë‹ˆë‹¤"),
])
async def test_remove_translation_style(translated, natural):
    """ë²ˆì—­ì²´ ì œê±°"""
    result = await copywriter.process_paragraph(translated)

    # ë²ˆì—­ì²´ í‘œí˜„ ì œê±° í™•ì¸
    translation_style = [
        "~ë˜ì–´ì§€ë‹¤", "~ëœë‹¤", "ê²ƒì´ë‹¤", "~ì— ì˜í•´"
    ]
    for style in translation_style:
        assert style not in result.edited_text, f"{style} ë‚¨ì•„ìˆìŒ"

    # ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ í™•ì¸
    assert similar(result.edited_text, natural) > 0.8
```

#### C.4 í’ˆì§ˆ ê¸°ì¤€

```python
class CopywritingAcceptanceCriteria:
    """ìœ¤ë¬¸ ëª¨ë“ˆ ìˆ˜ìš© ê¸°ì¤€"""

    def validate(self, result: EditResult) -> bool:
        checks = {
            "readability_improvement": \
                result.readability_score > \
                result.original_readability + 10,
            "tone_consistency": result.tone_score > 0.95,
            "intent_preservation": result.semantic_similarity > 0.95,
            "translation_style_removed": \
                result.translation_style_count == 0,
            "processing_time": result.processing_time < 180,  # <3ë¶„/ë‹¨ë½
            "quality_score": result.quality_score >= 85,
        }

        return all(checks.values())
```

---

## ğŸ“Š í†µí•© ì‹œë‚˜ë¦¬ì˜¤ (Integration Scenarios)

### ì‹œë‚˜ë¦¬ì˜¤ 9: ë‹¨ì¼ ë¬¸ì„œ ì „ì²´ í¸ì§‘

```gherkin
Given: ë²ˆì—­ ì™„ë£Œëœ 50K ë‹¨ì–´ ë¬¸ì„œ (LAF)
When: ì „ì²´ í¸ì§‘ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
Then:
  âœ… 1ë‹¨ê³„: êµì • ì™„ë£Œ (2-3ì‹œê°„)
  âœ… 2ë‹¨ê³„: êµì—´ ì™„ë£Œ (2-3ì‹œê°„)
  âœ… 3ë‹¨ê³„: ìœ¤ë¬¸ ì™„ë£Œ (2-3ì‹œê°„)
  âœ… ìµœì¢… í’ˆì§ˆ: â‰¥90ì 
  âœ… ëª¨ë“  ë³€ê²½ì‚¬í•­ ê¸°ë¡ë¨
  âœ… ìµœì¢… ë§ˆí¬ë‹¤ìš´ ìƒì„±ë¨
```

**êµ¬í˜„ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_single_document_full_edit():
    """ë‹¨ì¼ ë¬¸ì„œ ì „ì²´ í¸ì§‘"""
    doc = load_test_document("laf", size="50K")

    start = time.time()
    result = await orchestrator.edit_comprehensive(doc)
    elapsed = time.time() - start

    # í’ˆì§ˆ ê²€ì¦
    assert result.quality_score >= 90, \
        f"í’ˆì§ˆ ì ìˆ˜ ë¯¸ë‹¬: {result.quality_score}"

    # ì‹œê°„ ê²€ì¦ (ì˜ˆìƒ 8ì‹œê°„, ìµœëŒ€ 10ì‹œê°„)
    max_time = 36000  # 10ì‹œê°„
    assert elapsed < max_time, \
        f"ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼: {elapsed/3600:.1f}ì‹œê°„"

    # ê° ë‹¨ê³„ë³„ ì ìˆ˜ ê²€ì¦
    assert result.proofreading_score >= 85
    assert result.fact_checking_score >= 80
    assert result.copywriting_score >= 85

    # ë³€ê²½ì‚¬í•­ ê¸°ë¡ ê²€ì¦
    assert len(result.all_changes) > 0
    assert result.audit_log is not None

    # ìµœì¢… íŒŒì¼ ìƒì„± ê²€ì¦
    output_path = f"output/{doc.id}_edited.md"
    assert Path(output_path).exists()
```

### ì‹œë‚˜ë¦¬ì˜¤ 10: ë°°ì¹˜ ì²˜ë¦¬ (4ê°œ ë¬¸ì„œ)

```gherkin
Given: 4ê°œ ë²ˆì—­ ì™„ë£Œ ë¬¸ì„œ (LAF, SAF, SOSHR, CS)
When: ë°°ì¹˜ ì²˜ë¦¬ ëª¨ë“œ ì‹¤í–‰
Then:
  âœ… ê³µí†µ ìš©ì–´ì§‘ ìë™ ìƒì„±
  âœ… ë¬¸ì„œë³„ ìˆœì°¨ ì²˜ë¦¬
  âœ… ëª¨ë“  ë¬¸ì„œ í’ˆì§ˆ â‰¥90ì 
  âœ… ë¬¸ì„œ ê°„ ìš©ì–´ ì¼ê´€ì„± â‰¥95%
```

**êµ¬í˜„ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_batch_processing():
    """ë°°ì¹˜ ì²˜ë¦¬"""
    documents = [
        load_test_document("laf", size="100K"),
        load_test_document("saf", size="80K"),
        load_test_document("soshr", size="60K"),
        load_test_document("cs", size="50K"),
    ]

    start = time.time()
    results = await orchestrator.batch_process(documents)
    elapsed = time.time() - start

    # ê³µí†µ ìš©ì–´ì§‘ ê²€ì¦
    glossary = orchestrator.get_shared_glossary()
    assert len(glossary) > 100, "ìš©ì–´ì§‘ ë¶€ì¡±"

    # ë¬¸ì„œë³„ í’ˆì§ˆ ê²€ì¦
    for result in results:
        assert result.quality_score >= 90, \
            f"{result.doc_id}: í’ˆì§ˆ ì ìˆ˜ ë¯¸ë‹¬"

    # ìš©ì–´ ì¼ê´€ì„± ê²€ì¦
    consistency = calculate_term_consistency(results)
    assert consistency >= 0.95, \
        f"ìš©ì–´ ì¼ê´€ì„± ë¶€ì¡±: {consistency:.2%}"

    # ì²˜ë¦¬ ì‹œê°„ ê²€ì¦ (ìˆœì°¨: ~40ì‹œê°„)
    max_time = 144000  # 40ì‹œê°„
    assert elapsed < max_time
```

### ì‹œë‚˜ë¦¬ì˜¤ 11: ì‚¬ìš©ì í”¼ë“œë°± ë°˜ì˜

```gherkin
Given: í¸ì§‘ ì™„ë£Œ ë¬¸ì„œ + ì‚¬ìš©ì ìˆ˜ì • ìš”ì²­
When: ë¶€ë¶„ ì¬í¸ì§‘ ì‹¤í–‰
Then:
  âœ… í•´ë‹¹ ë¶€ë¶„ë§Œ ì¬ì²˜ë¦¬
  âœ… ì „ì²´ ì¼ê´€ì„± ì¬ê²€ìˆ˜
  âœ… ìµœì¢… í’ˆì§ˆ â‰¥85ì 
```

**êµ¬í˜„ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_partial_reediting():
    """ë¶€ë¶„ ì¬í¸ì§‘"""
    # ë¨¼ì € ì „ì²´ í¸ì§‘
    doc = load_test_document()
    edited_doc = await orchestrator.edit_comprehensive(doc)

    # ì‚¬ìš©ì í”¼ë“œë°± (3ê°œ ë¶€ë¶„ ìˆ˜ì • ìš”ì²­)
    feedback = [
        {"section": "intro", "feedback": "ë” ì¹œê·¼í•˜ê²Œ"},
        {"section": "chapter2", "feedback": "ëª…í™•íˆ"},
        {"section": "conclusion", "feedback": "ê°„ê²°í•˜ê²Œ"},
    ]

    # ë¶€ë¶„ ì¬í¸ì§‘
    revised_doc = await orchestrator.partial_reediting(
        edited_doc,
        feedback
    )

    # ê²€ì¦
    assert revised_doc.quality_score >= 85
    assert len(revised_doc.all_changes) > \
           len(edited_doc.all_changes)  # ë³€ê²½ì‚¬í•­ ì¦ê°€

    # ì¼ê´€ì„± ì¬ê²€ìˆ˜
    consistency = orchestrator.verify_consistency(revised_doc)
    assert consistency >= 0.95
```

### ì‹œë‚˜ë¦¬ì˜¤ 12: ì˜¤ë¥˜ ë³µêµ¬

```gherkin
Given: í¸ì§‘ ì§„í–‰ ì¤‘ API ì˜¤ë¥˜ ë°œìƒ
When: ì‹œìŠ¤í…œì´ ì˜¤ë¥˜ ê°ì§€
Then:
  âœ… ì¦‰ì‹œ ì¤‘ë‹¨ (ì§„í–‰ ìƒí™© ë³´ì¡´)
  âœ… ì˜¤ë¥˜ ì›ì¸ ëª…í™•íˆ ê¸°ë¡
  âœ… ì²´í¬í¬ì¸íŠ¸ì—ì„œ ë³µêµ¬ ê°€ëŠ¥
  âœ… í•´ë‹¹ ë¶€ë¶„ë§Œ ì¬ì²˜ë¦¬
```

**êµ¬í˜„ í…ŒìŠ¤íŠ¸**:
```python
@pytest.mark.asyncio
async def test_error_recovery():
    """ì˜¤ë¥˜ ë³µêµ¬"""
    doc = load_test_document()

    # ì˜ë„ì  ì˜¤ë¥˜ ì£¼ì…
    with patch("anthropic.Anthropic.messages.create") as mock:
        # ì²˜ìŒ 10íšŒëŠ” ì„±ê³µ, 11íšŒë¶€í„° ì‹¤íŒ¨
        call_count = 0
        def side_effect(*args, **kwargs):
            nonlocal call_count
            call_count += 1
            if call_count > 10:
                raise APIError("Service unavailable")
            return create_mock_response()

        mock.side_effect = side_effect

        # í¸ì§‘ ì‹¤í–‰ (ì˜¤ë¥˜ ë°œìƒ)
        try:
            await orchestrator.edit_comprehensive(doc)
        except APIError:
            pass

        # ë³µêµ¬ ê²€ì¦
        checkpoint = orchestrator.load_checkpoint(doc.id)
        assert checkpoint is not None, "ì²´í¬í¬ì¸íŠ¸ ì—†ìŒ"
        assert checkpoint.stage == "proofreading"
        assert checkpoint.chunk_num == 10

        # ê³„ì† ì§„í–‰ ê°€ëŠ¥í•œì§€ í™•ì¸
        mock.side_effect = None  # ì˜¤ë¥˜ í•´ì œ
        result = await orchestrator.resume_editing(doc.id)
        assert result is not None
```

---

## ğŸ“ˆ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

```python
class PerformanceBenchmarks:
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""

    @pytest.mark.benchmark
    async def test_proofreading_speed(self, benchmark):
        """êµì • ì†ë„"""
        agent = FormatExpertAgent(config)
        doc = create_test_document(size="small")

        def run():
            return asyncio.run(agent.process(doc))

        result = benchmark(run)
        assert result.quality_score >= 80

    @pytest.mark.benchmark
    async def test_fact_checking_speed(self, benchmark):
        """êµì—´ ì†ë„"""
        agent = FactCheckerAgent(config)
        doc = create_test_document(size="small")

        def run():
            return asyncio.run(agent.process(doc))

        result = benchmark(run)
        # Context7 í˜¸ì¶œ í¬í•¨, ì‹œê°„ì´ ë‹¤ì†Œ ê±¸ë¦¼
        assert result is not None

    @pytest.mark.benchmark
    async def test_copywriting_speed(self, benchmark):
        """ìœ¤ë¬¸ ì†ë„"""
        agent = CopywritingExpertAgent(config)
        doc = create_test_document(size="small")

        def run():
            return asyncio.run(agent.process(doc))

        result = benchmark(run)
        assert result.quality_score >= 80
```

### í™•ì¥ì„± í…ŒìŠ¤íŠ¸

```python
@pytest.mark.asyncio
async def test_scalability_large_document():
    """ëŒ€ìš©ëŸ‰ ë¬¸ì„œ ì²˜ë¦¬"""
    doc = load_test_document("laf", size="200K")  # 200K ë‹¨ì–´

    start = time.time()
    result = await orchestrator.edit_comprehensive(doc)
    elapsed = time.time() - start

    # ì„ í˜• í™•ì¥ì„± ê²€ì¦
    # 50K â†’ 8ì‹œê°„ì´ë©´, 200K â†’ 32ì‹œê°„ ì˜ˆìƒ
    expected_max = 32 * 3600 * 1.5  # 1.5ë°° ì—¬ìœ 
    assert elapsed < expected_max, "í™•ì¥ì„± ë¬¸ì œ"

    assert result.quality_score >= 85
```

---

## ğŸ“ ë°ì´í„° ê¸°ë°˜ ê²€ì¦

### í’ˆì§ˆ ë©”íŠ¸ë¦­ ì •ì˜

**êµì • ë©”íŠ¸ë¦­**:
```python
class ProofreadingMetrics:
    spelling_errors: int          # ë°œê²¬ëœ ë§ì¶¤ë²• ì˜¤ë¥˜
    spacing_errors: int           # ë„ì–´ì“°ê¸° ì˜¤ë¥˜
    notation_inconsistencies: int # í‘œê¸°ë²• ë¶ˆì¼ì¹˜
    typos: int                    # ì˜¤íƒ€
    duplicates: int               # ì¤‘ë³µ í‘œí˜„
    accuracy_rate: float          # = (ë°œê²¬+ìˆ˜ì •) / ì´_ë¬¸ììˆ˜
```

**êµì—´ ë©”íŠ¸ë¦­**:
```python
class FactCheckingMetrics:
    verified_items: int           # ê²€ì¦ëœ í•­ëª© ìˆ˜
    confidence_score: float       # í‰ê·  ì‹ ë¢°ë„ (0-1)
    deprecated_items: int         # êµ¬ì‹ ì •ë³´ ìˆ˜
    sources_cited: int            # ì¸ìš© ì¶œì²˜ ìˆ˜
    coverage_rate: float          # ê²€ì¦ìœ¨ (ê²€ì¦í•­ëª©/ì „ì²´í•­ëª©)
```

**ìœ¤ë¬¸ ë©”íŠ¸ë¦­**:
```python
class CopywritingMetrics:
    readability_improvement: int  # ê°€ë…ì„± ì¦ë¶„
    tone_consistency: float       # í†¤ ì¼ê´€ì„± (0-1)
    intent_preservation: float    # ì˜ë„ ë³´ì¡´ìœ¨ (0-1)
    sentence_simplification: int  # ë‹¨ìˆœí™”ëœ ë¬¸ì¥ ìˆ˜
    translation_style_count: int  # ë²ˆì—­ì²´ í‘œí˜„ ìˆ˜ (0ì´ì–´ì•¼ í•¨)
```

---

## âœ… ìµœì¢… ìˆ˜ìš© ì²´í¬ë¦¬ìŠ¤íŠ¸

```markdown
## Phase 1: ê¸°ë°˜ ì¸í”„ë¼
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ì™„ì„±
- [ ] ëª¨ë“  ë°ì´í„° ëª¨ë¸ ì •ì˜
- [ ] ì„¤ì • ì‹œìŠ¤í…œ êµ¬í˜„
- [ ] ë¡œê¹… ë° ì¶”ì  ì‹œìŠ¤í…œ êµ¬í˜„

## Phase 2: êµì • ëª¨ë“ˆ
- [ ] FormatExpertAgent êµ¬í˜„
- [ ] ë„ì–´ì“°ê¸° êµì • â‰¥95% ì •í™•ë„
- [ ] ì™¸êµ­ì–´ í‘œê¸°ë²• â‰¥95% ì¼ê´€ì„±
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ â‰¥80% ì»¤ë²„ë¦¬ì§€
- [ ] ì„±ëŠ¥: ì²­í¬ë‹¹ <5ì´ˆ

## Phase 3: êµì—´ ëª¨ë“ˆ
- [ ] FactCheckerAgent êµ¬í˜„
- [ ] Context7 MCP í†µí•©
- [ ] íŒ©íŠ¸ ê²€ì¦ â‰¥90% ì»¤ë²„ë¦¬ì§€
- [ ] êµ¬ì‹ ì •ë³´ ì‹ë³„ â‰¥80% ì •í™•ë„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ â‰¥80% ì»¤ë²„ë¦¬ì§€

## Phase 4: ìœ¤ë¬¸ ëª¨ë“ˆ
- [ ] CopywritingExpertAgent êµ¬í˜„
- [ ] ê°€ë…ì„± ê°œì„  â‰¥10ì 
- [ ] í†¤ ì¼ê´€ì„± â‰¥95%
- [ ] ì˜ë„ ë³´ì¡´ â‰¥95%
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ â‰¥80% ì»¤ë²„ë¦¬ì§€

## Phase 5: í†µí•© ë° ìµœì í™”
- [ ] ì „ì²´ E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ë°°ì¹˜ ì²˜ë¦¬ ë™ì‘
- [ ] ì˜¤ë¥˜ ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜ ë™ì‘
- [ ] LAF íŒŒì¼ëŸ¿ ì™„ë£Œ
- [ ] ìµœì¢… ë¬¸ì„œí™” ì™„ë£Œ

## ìµœì¢… í’ˆì§ˆ ê²Œì´íŠ¸
- [ ] ì „ì²´ í’ˆì§ˆ ì ìˆ˜ â‰¥90ì 
- [ ] ì˜¤ë¥˜ìœ¨ <1%
- [ ] ëª¨ë“  ìë™í™” í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] ìˆ˜ë™ ê²€ìˆ˜ ì™„ë£Œ
- [ ] í”„ë¡œë•ì…˜ ë°°í¬ ìŠ¹ì¸
```

---

## ğŸ“‹ ë‹¤ìŒ ë‹¨ê³„

1. âœ… 3ê°œ SPEC ë¬¸ì„œ ì‘ì„± ì™„ë£Œ
   - spec.md: ìš”êµ¬ì‚¬í•­ (EARS í˜•ì‹)
   - plan.md: êµ¬í˜„ ê³„íš (5 Phase)
   - acceptance.md: ìˆ˜ìš© ê¸°ì¤€ (Given-When-Then)

2. â³ Phase 1 êµ¬í˜„ ì‹œì‘
3. â³ ì£¼ê°„ ì§„í–‰ ìƒí™© ë¦¬ë·°
4. â³ íŒŒì¼ëŸ¿ í…ŒìŠ¤íŠ¸ (LAF)
5. â³ ìµœì¢… ë°°í¬ ë° í™•ëŒ€

---

## ğŸ”— ì°¸ê³  ìë£Œ

- [EARS Format Guide](https://www.incose.org/products-and-publications/products/requirements-format-guide)
- [Given-When-Then Testing](https://cucumber.io/docs/gherkin/)
- [Anthropic Claude API](https://docs.anthropic.com)
- [Context7 MCP Documentation](https://context7.upstash.com)
